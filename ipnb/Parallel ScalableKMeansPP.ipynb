{
 "metadata": {
  "name": "",
  "signature": "sha256:65c41824554e2d37b25a0fef0c82e82bfd2ef719af992cdc5b0c0ccecdcdf94e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "from IPython import parallel\n",
      "import KMeansBase\n",
      "import KMeansPP"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rc = parallel.Client()\n",
      "# load balanced view\n",
      "d_view = rc[:]\n",
      "# do synchronized processing\n",
      "d_view.block=True\n",
      "\n",
      "# import Numpy\n",
      "with d_view.sync_imports():\n",
      "    import numpy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "importing numpy on engine(s)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def initial_centroids(data, k):\n",
      "    ''' select k random data points from the data'''\n",
      "    return data[numpy.random.choice(range(data.shape[0]), k, replace=False)]\n",
      "\n",
      "def compare_centroids(old_centroids, new_centroids, precision=-1):\n",
      "    if precision == -1:\n",
      "        return numpy.array_equal(old_centroids, new_centroids)\n",
      "    else:\n",
      "        diff = numpy.sum((new_centroids - old_centroids)**2, axis=1)\n",
      "        if numpy.max(diff) <= precision:\n",
      "            return True\n",
      "        else:\n",
      "            return False\n",
      "\n",
      "def lloyds_iteration(data, centroids):\n",
      "    # find the Euclidean distance between a center and a data point\n",
      "    # centroids array shape = k x m\n",
      "    # data array shape = n x m\n",
      "    # In order to broadcast it, we have to introduce a third dimension into data\n",
      "    # data array becomes n x 1 x m\n",
      "    # now as a result of broadcasting, both array sizes will be n x k x m\n",
      "    data_ex = data[:, numpy.newaxis, :]\n",
      "    euclidean_dist = (data_ex - centroids) ** 2\n",
      "    # now take the summation of all distances along the 3rd axis(length of the dimension is m).\n",
      "    # This will be the total distance from each centroid for each data point.\n",
      "    # resulting vector will be of size n x k\n",
      "    distance_arr = numpy.sum(euclidean_dist, axis=2)\n",
      "\n",
      "    # now we need to find out to which cluster each data point belongs.\n",
      "    # Use a matrix of n x k where [i,j] = 1 if the ith data point belongs\n",
      "    # to cluster j.\n",
      "    min_location = numpy.zeros(distance_arr.shape)\n",
      "    min_location[range(distance_arr.shape[0]), numpy.argmin(distance_arr, axis=1)] = 1\n",
      "\n",
      "    # calculate J\n",
      "    j_val = numpy.sum(distance_arr[min_location == True])\n",
      "\n",
      "    # calculates the new centroids\n",
      "    new_centroids = numpy.empty(centroids.shape)\n",
      "    membership_count = numpy.empty(centroids.shape[0])\n",
      "    for col in range(0, centroids.shape[0]):\n",
      "        new_centroids[col] = numpy.mean(data[min_location[:, col] == True, :], axis=0)\n",
      "        membership_count[col] = numpy.count_nonzero(min_location[:, col])\n",
      "        \n",
      "    return {'j-value':j_val, 'centroids':new_centroids, 'element-count':membership_count}\n",
      "\n",
      "def ScalableKMeansPP(data, l, centroids):\n",
      "    data_ex = data[:, numpy.newaxis, :]\n",
      "    euclidean_dist = (data_ex - centroids) ** 2\n",
      "    distance_arr = numpy.sum(euclidean_dist, axis=2)\n",
      "    # find the minimum distance, this will be the weight\n",
      "    min = numpy.min(distance_arr, axis=1).reshape(-1, 1)\n",
      "    # let's use weighted reservoir sampling algorithm to select l centroids\n",
      "    random_numbers = numpy.random.rand(min.shape[0], min.shape[1])\n",
      "    # replace zeros in min if available with the lowest positive float in Python\n",
      "    min[numpy.where(min==0)] = numpy.nextafter(0,1)\n",
      "    # take the n^th root of random numbers where n is the weights\n",
      "    with numpy.errstate(all='ignore'):\n",
      "        random_numbers = random_numbers ** (1.0/min)\n",
      "    # pick the highest l\n",
      "    cent = data[numpy.argsort(random_numbers, axis=0)[:, 0]][::-1][:l, :]\n",
      "    # combine the new set of centroids with the previous set\n",
      "    centroids = numpy.vstack((centroids, cent))\n",
      "    # now we have the initial set of centroids which is higher than k.\n",
      "    # we should reduce this to k using scalable K-Means++\n",
      "    euclidean_dist = (data_ex - centroids) ** 2\n",
      "    distance_arr = numpy.sum(euclidean_dist, axis=2)\n",
      "    min_location = numpy.zeros(distance_arr.shape)\n",
      "    min_location[range(distance_arr.shape[0]), numpy.argmin(distance_arr, axis=1)] = 1\n",
      "    weights = numpy.array([numpy.count_nonzero(min_location[:, col]) for col in range(centroids.shape[0])]).reshape(-1,1)\n",
      "    return {'centroids': centroids, 'weights': weights}\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = numpy.random.randn(1000000,2)\n",
      "# distribute the data among the engines\n",
      "d_view.scatter('data', data)\n",
      "\n",
      "# first pick a random centroid. Ask one engine to pick the first random centroid\n",
      "centroids = rc[0].apply(initial_centroids, parallel.Reference('data'),1).get()\n",
      "\n",
      "r = 3\n",
      "l = 2\n",
      "k = 4\n",
      "passes = 0\n",
      "while passes < r:\n",
      "    result = d_view.apply(ScalableKMeansPP, parallel.Reference('data'), l, centroids)\n",
      "    print('centroids from one engine: ', result[0]['centroids'].shape)\n",
      "    # combine the centroids for the next iteration\n",
      "    centroids = numpy.vstack(r['centroids'] for r in result)\n",
      "    passes += 1\n",
      "# next step is to calculate k centroids out of the centroids returned by each engine\n",
      "# for this we use KMeans++\n",
      "weights = numpy.vstack(r['weights'] for r in result)\n",
      "kmeans_pp = KMeansPP.KMeansPP(weights, k)\n",
      "_, _, _, min_locations = kmeans_pp.cluster()\n",
      "# calculates the new centroids\n",
      "new_centroids = numpy.empty((k, data.shape[1]))\n",
      "for col in range(0, k):\n",
      "    new_centroids[col] = numpy.mean(centroids[min_locations[:, col] == True, :], axis=0)\n",
      "\n",
      "centroids = new_centroids\n",
      "# now do the lloyd's iterations\n",
      "stabilized = False\n",
      "iterations = 0\n",
      "while not stabilized:\n",
      "    iterations += 1\n",
      "    ret_vals = d_view.apply(lloyds_iteration, parallel.Reference('data'), centroids)\n",
      "    member_count = numpy.sum(numpy.array([r['element-count'] for r in ret_vals]).reshape(len(ret_vals),-1),axis=0)\n",
      "    local_sum = numpy.array([r['centroids'] * r['element-count'].reshape(-1,1) for r in ret_vals])\n",
      "    new_centroids = numpy.sum(local_sum, axis=0)/member_count.reshape(-1,1)\n",
      "    if compare_centroids(centroids, new_centroids):\n",
      "        stabilized = True\n",
      "    else:\n",
      "        centroids = new_centroids\n",
      "\n",
      "print('Iterations:', iterations)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "centroids from one engine:  (3, 2)\n",
        "centroids from one engine: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (14, 2)\n",
        "centroids from one engine: "
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    }
   ],
   "metadata": {}
  }
 ]
}